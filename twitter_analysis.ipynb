{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1fadd3d3",
      "metadata": {
        "papermill": {
          "duration": 0.028355,
          "end_time": "2022-12-01T13:03:37.892919",
          "exception": false,
          "start_time": "2022-12-01T13:03:37.864564",
          "status": "completed"
        },
        "tags": [],
        "id": "1fadd3d3"
      },
      "source": [
        "\n",
        "\n",
        "<h1 style='; border:0; border-radius: 10px; text-shadow: 1px 1px black; font-weight: bold; color:#4D1873'><center> Twitter-Sentiment-Analysis:\n",
        "Detecting Hate Speech in Tweets Using ML\n",
        "</center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88892340",
      "metadata": {
        "papermill": {
          "duration": 0.025238,
          "end_time": "2022-12-01T13:03:37.995235",
          "exception": false,
          "start_time": "2022-12-01T13:03:37.969997",
          "status": "completed"
        },
        "tags": [],
        "id": "88892340"
      },
      "source": [
        "<a id='top'></a>\n",
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "<p style=\"background-color:#4D1873; font-family:arial;color:#FFFFFF;font-size:170%;text-align:center;border-radius:55px 1px;\">INTRODUCTION</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "462d4f71",
      "metadata": {
        "papermill": {
          "duration": 0.026525,
          "end_time": "2022-12-01T13:03:38.047460",
          "exception": false,
          "start_time": "2022-12-01T13:03:38.020935",
          "status": "completed"
        },
        "tags": [],
        "id": "462d4f71"
      },
      "source": [
        "<div style=\"border-radius:5px;\n",
        "            border : black solid;\n",
        "            background-color: #E3E3E3;\n",
        "            text-align: left\">\n",
        "\n",
        "\n",
        "### <mark>Sentiment analysis</mark>\n",
        "<p style=\"text-align: left\">Sentiment analysis, is a specialized technique in natural language processing (NLP) that focuses on identifying and interpreting . Organizations employ sentiment analysis systems to derive insights from unstructured and unorganized data sources. These systems automate the analysis process, replacing the need for manual evaluation by using rule-based, automatic, or hybrid approaches.</p>\n",
        "\n",
        "###<mark>About :  </mark>\n",
        "<p>This project focused on developing a machine learning model to predict  hate speech in tweets using machine learning techniques. Hate speech is identified as tweets containing racist or sexist sentiments. The goal is to classify tweets into two categories:</p>\n",
        "<ul>\n",
        "<li> Contains hate speech (racist/sexist)</li>\n",
        "<li> Does not contain hate speech.</li>\n",
        "</ul>\n",
        "\n",
        "By leveraging data preprocessing,\n",
        " feature engineering (e.g., TF-IDF, word embeddings), and classification models (e.g., Logistic Regression, SVM, Random Forest,Gradient Boosting (e.g., XGBoost, LightGBM)), <p>This aims to build a system for automated content moderation, ensuring safer online environments and supporting business needs like legal compliance and brand protection.</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a987081",
      "metadata": {
        "papermill": {
          "duration": 0.024599,
          "end_time": "2022-12-01T13:03:38.098584",
          "exception": false,
          "start_time": "2022-12-01T13:03:38.073985",
          "status": "completed"
        },
        "tags": [],
        "id": "2a987081"
      },
      "source": [
        "<a id='top'></a>\n",
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "<p style=\"background-color:#4D1873 ;font-family:arial;color:#FFFFFF;font-size:170%;text-align:center;border-radius:55px 1px;\">IMPORT NECESSARY LIBRARIES</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "78739177",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:38.152691Z",
          "iopub.status.busy": "2022-12-01T13:03:38.151478Z",
          "iopub.status.idle": "2022-12-01T13:03:44.243591Z",
          "shell.execute_reply": "2022-12-01T13:03:44.236291Z"
        },
        "papermill": {
          "duration": 6.125629,
          "end_time": "2022-12-01T13:03:44.249990",
          "exception": false,
          "start_time": "2022-12-01T13:03:38.124361",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78739177",
        "outputId": "58ee63cd-1d52-4e1e-b297-78b8fc654c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LIBRARIES WERE SUCCESFULLY IMPORTED...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import model_selection, preprocessing, linear_model, metrics\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import ensemble\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from termcolor import colored\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(print_changed_only = False)\n",
        "\n",
        "print(colored(\"\\nLIBRARIES WERE SUCCESFULLY IMPORTED...\", color = \"blue\", attrs = [\"dark\", \"bold\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e766bccc",
      "metadata": {
        "papermill": {
          "duration": 0.051146,
          "end_time": "2022-12-01T13:03:44.350215",
          "exception": false,
          "start_time": "2022-12-01T13:03:44.299069",
          "status": "completed"
        },
        "tags": [],
        "id": "e766bccc"
      },
      "source": [
        "<a id='top'></a>\n",
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "<p style=\"background-color:#4D1873 ;font-family:arial;color:#FFFFFF;font-size:170%;text-align:center;border-radius:55px 1px;\">LOAD DATASETS</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "759f0a75",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:44.456959Z",
          "iopub.status.busy": "2022-12-01T13:03:44.455678Z",
          "iopub.status.idle": "2022-12-01T13:03:45.218552Z",
          "shell.execute_reply": "2022-12-01T13:03:45.217124Z"
        },
        "papermill": {
          "duration": 0.829446,
          "end_time": "2022-12-01T13:03:45.228910",
          "exception": false,
          "start_time": "2022-12-01T13:03:44.399464",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "759f0a75",
        "outputId": "7cb503c2-1bc6-4d47-9beb-14f510690816"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-04a236ce2f58>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_set = pd.read_csv(\"/train.csv\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                    \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    header = 0)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/train.csv'"
          ]
        }
      ],
      "source": [
        "train_set = pd.read_csv(\"/train.csv\",\n",
        "                   encoding = \"utf-8\",\n",
        "                   engine = \"python\",\n",
        "                   header = 0)\n",
        "\n",
        "test_set = pd.read_csv(\"/test.csv\",\n",
        "                   encoding = \"utf-8\",\n",
        "                   engine = \"python\",\n",
        "                   header = 0)\n",
        "\n",
        "print(colored(\"\\nDATASETS WERE SUCCESFULLY LOADED...\", color = \"blue\", attrs = [\"dark\", \"bold\"]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UckMGo6CdJPZ"
      },
      "id": "UckMGo6CdJPZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1c113605",
      "metadata": {
        "papermill": {
          "duration": 0.076424,
          "end_time": "2022-12-01T13:03:45.413319",
          "exception": false,
          "start_time": "2022-12-01T13:03:45.336895",
          "status": "completed"
        },
        "tags": [],
        "id": "1c113605"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">The first five rows of train set</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e15c839d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:45.584067Z",
          "iopub.status.busy": "2022-12-01T13:03:45.583437Z",
          "iopub.status.idle": "2022-12-01T13:03:45.817736Z",
          "shell.execute_reply": "2022-12-01T13:03:45.816396Z"
        },
        "papermill": {
          "duration": 0.324912,
          "end_time": "2022-12-01T13:03:45.822510",
          "exception": false,
          "start_time": "2022-12-01T13:03:45.497598",
          "status": "completed"
        },
        "tags": [],
        "id": "e15c839d"
      },
      "outputs": [],
      "source": [
        "train_set.head(n = 5).style.background_gradient(cmap = \"summer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5abb1f69",
      "metadata": {
        "papermill": {
          "duration": 0.049464,
          "end_time": "2022-12-01T13:03:45.920383",
          "exception": false,
          "start_time": "2022-12-01T13:03:45.870919",
          "status": "completed"
        },
        "tags": [],
        "id": "5abb1f69"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">The first five rows of test set</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fe8e931",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:46.010147Z",
          "iopub.status.busy": "2022-12-01T13:03:46.008674Z",
          "iopub.status.idle": "2022-12-01T13:03:46.027264Z",
          "shell.execute_reply": "2022-12-01T13:03:46.025847Z"
        },
        "papermill": {
          "duration": 0.06204,
          "end_time": "2022-12-01T13:03:46.030961",
          "exception": false,
          "start_time": "2022-12-01T13:03:45.968921",
          "status": "completed"
        },
        "tags": [],
        "id": "0fe8e931"
      },
      "outputs": [],
      "source": [
        "test_set.head(n = 5).style.background_gradient(cmap = \"summer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a8169c4",
      "metadata": {
        "papermill": {
          "duration": 0.027991,
          "end_time": "2022-12-01T13:03:46.088012",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.060021",
          "status": "completed"
        },
        "tags": [],
        "id": "2a8169c4"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Shapes of the train and test sets</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d06e49e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:46.145770Z",
          "iopub.status.busy": "2022-12-01T13:03:46.145316Z",
          "iopub.status.idle": "2022-12-01T13:03:46.152112Z",
          "shell.execute_reply": "2022-12-01T13:03:46.150875Z"
        },
        "papermill": {
          "duration": 0.039683,
          "end_time": "2022-12-01T13:03:46.155820",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.116137",
          "status": "completed"
        },
        "tags": [],
        "id": "3d06e49e"
      },
      "outputs": [],
      "source": [
        "print(\"Train set shape: {} and test set shape: {}\".format(train_set.shape, test_set.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97c19235",
      "metadata": {
        "papermill": {
          "duration": 0.027358,
          "end_time": "2022-12-01T13:03:46.210180",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.182822",
          "status": "completed"
        },
        "tags": [],
        "id": "97c19235"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Get general information about train set</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d7fb36",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:46.265702Z",
          "iopub.status.busy": "2022-12-01T13:03:46.264648Z",
          "iopub.status.idle": "2022-12-01T13:03:46.292682Z",
          "shell.execute_reply": "2022-12-01T13:03:46.291009Z"
        },
        "papermill": {
          "duration": 0.059321,
          "end_time": "2022-12-01T13:03:46.295578",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.236257",
          "status": "completed"
        },
        "tags": [],
        "id": "e3d7fb36"
      },
      "outputs": [],
      "source": [
        "train_set.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d511ce18",
      "metadata": {
        "papermill": {
          "duration": 0.025765,
          "end_time": "2022-12-01T13:03:46.348198",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.322433",
          "status": "completed"
        },
        "tags": [],
        "id": "d511ce18"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Check whether there are duplicated values</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2baf443b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:46.409482Z",
          "iopub.status.busy": "2022-12-01T13:03:46.408593Z",
          "iopub.status.idle": "2022-12-01T13:03:46.438969Z",
          "shell.execute_reply": "2022-12-01T13:03:46.437645Z"
        },
        "papermill": {
          "duration": 0.063086,
          "end_time": "2022-12-01T13:03:46.442255",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.379169",
          "status": "completed"
        },
        "tags": [],
        "id": "2baf443b"
      },
      "outputs": [],
      "source": [
        "print(\"Totally there are {} duplicated values in train_set\".format(train_set.duplicated().sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9916a04f",
      "metadata": {
        "papermill": {
          "duration": 0.028027,
          "end_time": "2022-12-01T13:03:46.496449",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.468422",
          "status": "completed"
        },
        "tags": [],
        "id": "9916a04f"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Get the number of classes of the \"label\" variable of train set</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce9b296",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:46.554096Z",
          "iopub.status.busy": "2022-12-01T13:03:46.553374Z",
          "iopub.status.idle": "2022-12-01T13:03:46.581223Z",
          "shell.execute_reply": "2022-12-01T13:03:46.579758Z"
        },
        "papermill": {
          "duration": 0.060152,
          "end_time": "2022-12-01T13:03:46.584498",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.524346",
          "status": "completed"
        },
        "tags": [],
        "id": "1ce9b296"
      },
      "outputs": [],
      "source": [
        "train_set.groupby(\"label\").count().style.background_gradient(cmap = \"summer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9fbe446",
      "metadata": {
        "papermill": {
          "duration": 0.027634,
          "end_time": "2022-12-01T13:03:46.639146",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.611512",
          "status": "completed"
        },
        "tags": [],
        "id": "b9fbe446"
      },
      "source": [
        "<a id='top'></a>\n",
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "<p style=\"background-color:#4D1873 ;font-family:arial;color:#FFFFFF;font-size:170%;text-align:center;border-radius:55px 1px;\">CLEAN AND PROCESS DATASET</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaf85d68",
      "metadata": {
        "papermill": {
          "duration": 0.026799,
          "end_time": "2022-12-01T13:03:46.693364",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.666565",
          "status": "completed"
        },
        "tags": [],
        "id": "eaf85d68"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Convert uppercase letters to lowercase letters in \"tweet\" columns</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b19af8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:46.751755Z",
          "iopub.status.busy": "2022-12-01T13:03:46.750880Z",
          "iopub.status.idle": "2022-12-01T13:03:46.983151Z",
          "shell.execute_reply": "2022-12-01T13:03:46.982004Z"
        },
        "papermill": {
          "duration": 0.264508,
          "end_time": "2022-12-01T13:03:46.986012",
          "exception": false,
          "start_time": "2022-12-01T13:03:46.721504",
          "status": "completed"
        },
        "tags": [],
        "id": "39b19af8"
      },
      "outputs": [],
      "source": [
        "train_set[\"tweet\"] = train_set[\"tweet\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "test_set[\"tweet\"] = test_set[\"tweet\"].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "print(colored(\"\\nCONVERTED SUCCESFULLY...\", color = \"blue\", attrs = [\"dark\", \"bold\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3508df1b",
      "metadata": {
        "papermill": {
          "duration": 0.027918,
          "end_time": "2022-12-01T13:03:47.043075",
          "exception": false,
          "start_time": "2022-12-01T13:03:47.015157",
          "status": "completed"
        },
        "tags": [],
        "id": "3508df1b"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Delete punctuation marks from \"tweet\" columns</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a21828",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:47.100764Z",
          "iopub.status.busy": "2022-12-01T13:03:47.099724Z",
          "iopub.status.idle": "2022-12-01T13:03:47.312823Z",
          "shell.execute_reply": "2022-12-01T13:03:47.311678Z"
        },
        "papermill": {
          "duration": 0.245338,
          "end_time": "2022-12-01T13:03:47.315540",
          "exception": false,
          "start_time": "2022-12-01T13:03:47.070202",
          "status": "completed"
        },
        "tags": [],
        "id": "a8a21828"
      },
      "outputs": [],
      "source": [
        "train_set[\"tweet\"] = train_set[\"tweet\"].str.replace('[^\\w\\s]','')\n",
        "test_set[\"tweet\"] = test_set[\"tweet\"].str.replace('[^\\w\\s]','')\n",
        "\n",
        "print(colored(\"\\nDELETED SUCCESFULLY...\", color = \"blue\", attrs = [\"dark\", \"bold\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "914bd65e",
      "metadata": {
        "papermill": {
          "duration": 0.02762,
          "end_time": "2022-12-01T13:03:47.369471",
          "exception": false,
          "start_time": "2022-12-01T13:03:47.341851",
          "status": "completed"
        },
        "tags": [],
        "id": "914bd65e"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Delete numbers from \"tweet\" columns</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bcce431",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:47.426524Z",
          "iopub.status.busy": "2022-12-01T13:03:47.426010Z",
          "iopub.status.idle": "2022-12-01T13:03:47.513703Z",
          "shell.execute_reply": "2022-12-01T13:03:47.512264Z"
        },
        "papermill": {
          "duration": 0.120479,
          "end_time": "2022-12-01T13:03:47.517188",
          "exception": false,
          "start_time": "2022-12-01T13:03:47.396709",
          "status": "completed"
        },
        "tags": [],
        "id": "7bcce431"
      },
      "outputs": [],
      "source": [
        "train_set['tweet'] = train_set['tweet'].str.replace('\\d','')\n",
        "test_set['tweet'] = test_set['tweet'].str.replace('\\d','')\n",
        "\n",
        "print(colored(\"\\n NUMBERS DELETED SUCCESFULLY...\", color = \"blue\", attrs = [\"dark\", \"bold\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f62b167",
      "metadata": {
        "papermill": {
          "duration": 0.025982,
          "end_time": "2022-12-01T13:03:47.570175",
          "exception": false,
          "start_time": "2022-12-01T13:03:47.544193",
          "status": "completed"
        },
        "tags": [],
        "id": "1f62b167"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Delete stopwords from \"tweet\" columns</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e73d654",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:47.626067Z",
          "iopub.status.busy": "2022-12-01T13:03:47.625404Z",
          "iopub.status.idle": "2022-12-01T13:03:49.374921Z",
          "shell.execute_reply": "2022-12-01T13:03:49.373661Z"
        },
        "papermill": {
          "duration": 1.780085,
          "end_time": "2022-12-01T13:03:49.377830",
          "exception": false,
          "start_time": "2022-12-01T13:03:47.597745",
          "status": "completed"
        },
        "tags": [],
        "id": "4e73d654"
      },
      "outputs": [],
      "source": [
        "sw = stopwords.words(\"english\")\n",
        "train_set['tweet'] = train_set['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
        "test_set['tweet'] = test_set['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
        "\n",
        "print(colored(\"\\nSTOPWORDS DELETED SUCCESFULLY...\", color = \"blue\", attrs = [\"dark\", \"bold\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16372040",
      "metadata": {
        "papermill": {
          "duration": 0.034482,
          "end_time": "2022-12-01T13:03:49.441704",
          "exception": false,
          "start_time": "2022-12-01T13:03:49.407222",
          "status": "completed"
        },
        "tags": [],
        "id": "16372040"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Lemmatization. That is, we get the roots of the words in the \"tweet\" columns</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7da50efc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:49.503609Z",
          "iopub.status.busy": "2022-12-01T13:03:49.503147Z",
          "iopub.status.idle": "2022-12-01T13:03:55.490559Z",
          "shell.execute_reply": "2022-12-01T13:03:55.488609Z"
        },
        "papermill": {
          "duration": 6.022011,
          "end_time": "2022-12-01T13:03:55.495645",
          "exception": false,
          "start_time": "2022-12-01T13:03:49.473634",
          "status": "completed"
        },
        "tags": [],
        "id": "7da50efc"
      },
      "outputs": [],
      "source": [
        "train_set['tweet'] = train_set['tweet'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "test_set['tweet'] = test_set['tweet'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "\n",
        "print(colored(\"\\nDONE SUCCESFULLY...\", color = \"blue\", attrs = [\"dark\", \"bold\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49b545f0",
      "metadata": {
        "papermill": {
          "duration": 0.042522,
          "end_time": "2022-12-01T13:03:55.587489",
          "exception": false,
          "start_time": "2022-12-01T13:03:55.544967",
          "status": "completed"
        },
        "tags": [],
        "id": "49b545f0"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Drop \"id\" column from datasets</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a147280",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:55.672980Z",
          "iopub.status.busy": "2022-12-01T13:03:55.672211Z",
          "iopub.status.idle": "2022-12-01T13:03:55.692971Z",
          "shell.execute_reply": "2022-12-01T13:03:55.691743Z"
        },
        "papermill": {
          "duration": 0.068384,
          "end_time": "2022-12-01T13:03:55.697679",
          "exception": false,
          "start_time": "2022-12-01T13:03:55.629295",
          "status": "completed"
        },
        "tags": [],
        "id": "9a147280"
      },
      "outputs": [],
      "source": [
        "train_set = train_set.drop(\"id\", axis = 1)\n",
        "test_set = test_set.drop(\"id\", axis = 1)\n",
        "\n",
        "print(colored(\"\\n'ID' COLUMNS DROPPED SUCCESFULLY...\", color = \"blue\", attrs = [\"dark\", \"bold\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01b8a3b2",
      "metadata": {
        "papermill": {
          "duration": 0.04161,
          "end_time": "2022-12-01T13:03:55.781087",
          "exception": false,
          "start_time": "2022-12-01T13:03:55.739477",
          "status": "completed"
        },
        "tags": [],
        "id": "01b8a3b2"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Look at the latest condition of train set\n",
        "</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b196207c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:55.872244Z",
          "iopub.status.busy": "2022-12-01T13:03:55.871508Z",
          "iopub.status.idle": "2022-12-01T13:03:55.898094Z",
          "shell.execute_reply": "2022-12-01T13:03:55.896655Z"
        },
        "papermill": {
          "duration": 0.08053,
          "end_time": "2022-12-01T13:03:55.902480",
          "exception": false,
          "start_time": "2022-12-01T13:03:55.821950",
          "status": "completed"
        },
        "tags": [],
        "id": "b196207c"
      },
      "outputs": [],
      "source": [
        "train_set.head(n = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cb01e17",
      "metadata": {
        "papermill": {
          "duration": 0.040424,
          "end_time": "2022-12-01T13:03:55.984642",
          "exception": false,
          "start_time": "2022-12-01T13:03:55.944218",
          "status": "completed"
        },
        "tags": [],
        "id": "2cb01e17"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Look at the latest condition of test set</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3445dc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:56.074418Z",
          "iopub.status.busy": "2022-12-01T13:03:56.073662Z",
          "iopub.status.idle": "2022-12-01T13:03:56.100656Z",
          "shell.execute_reply": "2022-12-01T13:03:56.099048Z"
        },
        "papermill": {
          "duration": 0.075505,
          "end_time": "2022-12-01T13:03:56.104065",
          "exception": false,
          "start_time": "2022-12-01T13:03:56.028560",
          "status": "completed"
        },
        "tags": [],
        "id": "3d3445dc"
      },
      "outputs": [],
      "source": [
        "test_set.head(n = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ecb1eca",
      "metadata": {
        "papermill": {
          "duration": 0.026539,
          "end_time": "2022-12-01T13:03:56.167597",
          "exception": false,
          "start_time": "2022-12-01T13:03:56.141058",
          "status": "completed"
        },
        "tags": [],
        "id": "9ecb1eca"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Divide datasets</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0320dc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:56.226014Z",
          "iopub.status.busy": "2022-12-01T13:03:56.225493Z",
          "iopub.status.idle": "2022-12-01T13:03:56.241279Z",
          "shell.execute_reply": "2022-12-01T13:03:56.239891Z"
        },
        "papermill": {
          "duration": 0.047722,
          "end_time": "2022-12-01T13:03:56.244123",
          "exception": false,
          "start_time": "2022-12-01T13:03:56.196401",
          "status": "completed"
        },
        "tags": [],
        "id": "8a0320dc"
      },
      "outputs": [],
      "source": [
        "x = train_set[\"tweet\"]\n",
        "y = train_set[\"label\"]\n",
        "\n",
        "train_x, test_x, train_y, test_y = model_selection.train_test_split(x, y, test_size = 0.20, shuffle = True, random_state = 11)\n",
        "\n",
        "print(colored(\"\\nDIVIDED SUCCESFULLY...\", color = \"blue\", attrs = [\"dark\", \"bold\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd610725",
      "metadata": {
        "papermill": {
          "duration": 0.027486,
          "end_time": "2022-12-01T13:03:56.299286",
          "exception": false,
          "start_time": "2022-12-01T13:03:56.271800",
          "status": "completed"
        },
        "tags": [],
        "id": "fd610725"
      },
      "source": [
        "<a id='top'></a>\n",
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "<p style=\"background-color:#4D1873 ;font-family:arial;color:#FFFFFF;font-size:170%;text-align:center;border-radius:55px 1px;\">VECTORIZE DATA</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Embeddings or Word vectorization is a methodology in NLP to map words or phrases from vocabulary to a corresponding vector of real numbers which used to find word predictions, word similarities/semantics"
      ],
      "metadata": {
        "id": "7KpDl972clET"
      },
      "id": "7KpDl972clET"
    },
    {
      "cell_type": "markdown",
      "id": "6d3b2070",
      "metadata": {
        "papermill": {
          "duration": 0.02749,
          "end_time": "2022-12-01T13:03:56.414164",
          "exception": false,
          "start_time": "2022-12-01T13:03:56.386674",
          "status": "completed"
        },
        "tags": [],
        "id": "6d3b2070"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">\"Count Vectors\" method</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e23b82e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:56.473708Z",
          "iopub.status.busy": "2022-12-01T13:03:56.472818Z",
          "iopub.status.idle": "2022-12-01T13:03:57.880939Z",
          "shell.execute_reply": "2022-12-01T13:03:57.879683Z"
        },
        "papermill": {
          "duration": 1.441477,
          "end_time": "2022-12-01T13:03:57.883825",
          "exception": false,
          "start_time": "2022-12-01T13:03:56.442348",
          "status": "completed"
        },
        "tags": [],
        "id": "9e23b82e"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(train_x)\n",
        "\n",
        "x_train_count = vectorizer.transform(train_x)\n",
        "x_test_count = vectorizer.transform(test_x)\n",
        "\n",
        "x_train_count.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa5958f3",
      "metadata": {
        "papermill": {
          "duration": 0.027801,
          "end_time": "2022-12-01T13:03:57.940266",
          "exception": false,
          "start_time": "2022-12-01T13:03:57.912465",
          "status": "completed"
        },
        "tags": [],
        "id": "fa5958f3"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">\"TF-IDF\" method</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1627308",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:03:57.998428Z",
          "iopub.status.busy": "2022-12-01T13:03:57.997662Z",
          "iopub.status.idle": "2022-12-01T13:04:00.158064Z",
          "shell.execute_reply": "2022-12-01T13:04:00.156962Z"
        },
        "papermill": {
          "duration": 2.192643,
          "end_time": "2022-12-01T13:04:00.160541",
          "exception": false,
          "start_time": "2022-12-01T13:03:57.967898",
          "status": "completed"
        },
        "tags": [],
        "id": "e1627308"
      },
      "outputs": [],
      "source": [
        "tf_idf_word_vectorizer = TfidfVectorizer()\n",
        "tf_idf_word_vectorizer.fit(train_x)\n",
        "\n",
        "x_train_tf_idf_word = tf_idf_word_vectorizer.transform(train_x)\n",
        "x_test_tf_idf_word = tf_idf_word_vectorizer.transform(test_x)\n",
        "\n",
        "x_train_tf_idf_word.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9311e788",
      "metadata": {
        "papermill": {
          "duration": 0.027874,
          "end_time": "2022-12-01T13:04:00.217411",
          "exception": false,
          "start_time": "2022-12-01T13:04:00.189537",
          "status": "completed"
        },
        "tags": [],
        "id": "9311e788"
      },
      "source": [
        "<a id='top'></a>\n",
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "<p style=\"background-color:#4D1873 ;font-family:arial;color:#FFFFFF;font-size:170%;text-align:center;border-radius:55px 1px;\">BUILD MACHINE LEARNING MODELS</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b63eb1d0",
      "metadata": {
        "papermill": {
          "duration": 0.029005,
          "end_time": "2022-12-01T13:04:00.274391",
          "exception": false,
          "start_time": "2022-12-01T13:04:00.245386",
          "status": "completed"
        },
        "tags": [],
        "id": "b63eb1d0"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Logistic regression model with \"count-vectors\" method</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1891d4cb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:04:00.333512Z",
          "iopub.status.busy": "2022-12-01T13:04:00.332419Z",
          "iopub.status.idle": "2022-12-01T13:04:27.906127Z",
          "shell.execute_reply": "2022-12-01T13:04:27.904303Z"
        },
        "papermill": {
          "duration": 27.608993,
          "end_time": "2022-12-01T13:04:27.911597",
          "exception": false,
          "start_time": "2022-12-01T13:04:00.302604",
          "status": "completed"
        },
        "tags": [],
        "id": "1891d4cb"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from termcolor import colored\n",
        "\n",
        "# Fit the Logistic Regression model\n",
        "log = LogisticRegression()\n",
        "log_model = log.fit(x_train_count, train_y)\n",
        "\n",
        "# Cross-validation accuracy score\n",
        "accuracy = cross_val_score(log_model,\n",
        "                           x_test_count,\n",
        "                           test_y,\n",
        "                           cv=20).mean()\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = log_model.predict(x_test_count)\n",
        "\n",
        "# Calculate precision, recall, and F1 score using sklearn\n",
        "precision = metrics.precision_score(test_y, y_pred)\n",
        "recall = metrics.recall_score(test_y, y_pred)\n",
        "f1 = metrics.f1_score(test_y, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(colored(\"\\nLogistic regression model with 'count-vectors' method\", color=\"red\", attrs=[\"dark\", \"bold\"]))\n",
        "print(colored(\"Accuracy ratio: \", color=\"red\", attrs=[\"dark\", \"bold\"]), accuracy)\n",
        "print(colored(\"Precision: \", color=\"red\", attrs=[\"dark\", \"bold\"]), precision)\n",
        "print(colored(\"Recall: \", color=\"red\", attrs=[\"dark\", \"bold\"]), recall)\n",
        "print(colored(\"F1 Score: \", color=\"red\", attrs=[\"dark\", \"bold\"]), f1)\n",
        "\n",
        "# Optionally, print a full classification report (including precision, recall, F1 score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(metrics.classification_report(test_y, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a304b7",
      "metadata": {
        "papermill": {
          "duration": 0.02983,
          "end_time": "2022-12-01T13:04:28.063103",
          "exception": false,
          "start_time": "2022-12-01T13:04:28.033273",
          "status": "completed"
        },
        "tags": [],
        "id": "c5a304b7"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Logistic regression model with \"tf-idf\" method</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dea2c527",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:04:28.123572Z",
          "iopub.status.busy": "2022-12-01T13:04:28.122686Z",
          "iopub.status.idle": "2022-12-01T13:04:44.481577Z",
          "shell.execute_reply": "2022-12-01T13:04:44.479771Z"
        },
        "papermill": {
          "duration": 16.395582,
          "end_time": "2022-12-01T13:04:44.487178",
          "exception": false,
          "start_time": "2022-12-01T13:04:28.091596",
          "status": "completed"
        },
        "tags": [],
        "id": "dea2c527"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from termcolor import colored\n",
        "\n",
        "# Fit the Logistic Regression model with TF-IDF features\n",
        "log = LogisticRegression()\n",
        "log_model = log.fit(x_train_tf_idf_word, train_y)\n",
        "\n",
        "# Cross-validation accuracy score\n",
        "accuracy = cross_val_score(log_model,\n",
        "                           x_test_tf_idf_word,\n",
        "                           test_y,\n",
        "                           cv=20).mean()\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = log_model.predict(x_test_tf_idf_word)\n",
        "\n",
        "# Calculate precision, recall, and F1 score using sklearn\n",
        "precision = metrics.precision_score(test_y, y_pred)\n",
        "recall = metrics.recall_score(test_y, y_pred)\n",
        "f1 = metrics.f1_score(test_y, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(colored(\"\\nLogistic regression model with 'tf-idf' method\", color=\"red\", attrs=[\"dark\", \"bold\"]))\n",
        "print(colored(\"Accuracy ratio: \", color=\"red\", attrs=[\"dark\", \"bold\"]), accuracy)\n",
        "print(colored(\"Precision: \", color=\"red\", attrs=[\"dark\", \"bold\"]), precision)\n",
        "print(colored(\"Recall: \", color=\"red\", attrs=[\"dark\", \"bold\"]), recall)\n",
        "print(colored(\"F1 Score: \", color=\"red\", attrs=[\"dark\", \"bold\"]), f1)\n",
        "\n",
        "# Optionally, print a full classification report (including precision, recall, F1 score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(metrics.classification_report(test_y, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad053c5a",
      "metadata": {
        "papermill": {
          "duration": 0.027794,
          "end_time": "2022-12-01T13:04:44.627677",
          "exception": false,
          "start_time": "2022-12-01T13:04:44.599883",
          "status": "completed"
        },
        "tags": [],
        "id": "ad053c5a"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">XGBoost model with \"count-vectors\" method</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcfa701f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:04:44.687478Z",
          "iopub.status.busy": "2022-12-01T13:04:44.687012Z",
          "iopub.status.idle": "2022-12-01T13:05:37.466986Z",
          "shell.execute_reply": "2022-12-01T13:05:37.465896Z"
        },
        "papermill": {
          "duration": 52.832967,
          "end_time": "2022-12-01T13:05:37.490081",
          "exception": false,
          "start_time": "2022-12-01T13:04:44.657114",
          "status": "completed"
        },
        "tags": [],
        "id": "fcfa701f"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from termcolor import colored\n",
        "\n",
        "# Fit the XGBoost model with 'count-vectors' method\n",
        "xgb = XGBClassifier()\n",
        "xgb_model = xgb.fit(x_train_count, train_y)\n",
        "\n",
        "# Cross-validation accuracy score\n",
        "accuracy = cross_val_score(xgb_model,\n",
        "                           x_test_count,\n",
        "                           test_y,\n",
        "                           cv=20).mean()\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = xgb_model.predict(x_test_count)\n",
        "\n",
        "# Calculate precision, recall, and F1 score using sklearn\n",
        "precision = metrics.precision_score(test_y, y_pred)\n",
        "recall = metrics.recall_score(test_y, y_pred)\n",
        "f1 = metrics.f1_score(test_y, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(colored(\"\\nXGBoost model with 'count-vectors' method\", color=\"red\", attrs=[\"dark\", \"bold\"]))\n",
        "print(colored(\"Accuracy ratio: \", color=\"red\", attrs=[\"dark\", \"bold\"]), accuracy)\n",
        "print(colored(\"Precision: \", color=\"red\", attrs=[\"dark\", \"bold\"]), precision)\n",
        "print(colored(\"Recall: \", color=\"red\", attrs=[\"dark\", \"bold\"]), recall)\n",
        "print(colored(\"F1 Score: \", color=\"red\", attrs=[\"dark\", \"bold\"]), f1)\n",
        "\n",
        "# Optionally, print a full classification report (including precision, recall, F1 score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(metrics.classification_report(test_y, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ff0d0c",
      "metadata": {
        "papermill": {
          "duration": 0.028998,
          "end_time": "2022-12-01T13:05:37.548572",
          "exception": false,
          "start_time": "2022-12-01T13:05:37.519574",
          "status": "completed"
        },
        "tags": [],
        "id": "55ff0d0c"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">XGBoost model with \"tf-idf\" method</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1b9504b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:05:37.607827Z",
          "iopub.status.busy": "2022-12-01T13:05:37.607355Z",
          "iopub.status.idle": "2022-12-01T13:06:43.981273Z",
          "shell.execute_reply": "2022-12-01T13:06:43.979937Z"
        },
        "papermill": {
          "duration": 66.433693,
          "end_time": "2022-12-01T13:06:44.010583",
          "exception": false,
          "start_time": "2022-12-01T13:05:37.576890",
          "status": "completed"
        },
        "tags": [],
        "id": "d1b9504b"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from termcolor import colored\n",
        "\n",
        "# Fit the XGBoost model with TF-IDF features\n",
        "xgb = XGBClassifier()\n",
        "xgb_model = xgb.fit(x_train_tf_idf_word, train_y)\n",
        "\n",
        "# Cross-validation accuracy score\n",
        "accuracy = cross_val_score(xgb_model,\n",
        "                           x_test_tf_idf_word,\n",
        "                           test_y,\n",
        "                           cv=20).mean()\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = xgb_model.predict(x_test_tf_idf_word)\n",
        "\n",
        "# Calculate precision, recall, and F1 score using sklearn\n",
        "precision = metrics.precision_score(test_y, y_pred)\n",
        "recall = metrics.recall_score(test_y, y_pred)\n",
        "f1 = metrics.f1_score(test_y, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(colored(\"\\nXGBoost model with 'tf-idf' method\", color=\"red\", attrs=[\"dark\", \"bold\"]))\n",
        "print(colored(\"Accuracy ratio: \", color=\"red\", attrs=[\"dark\", \"bold\"]), accuracy)\n",
        "print(colored(\"Precision: \", color=\"red\", attrs=[\"dark\", \"bold\"]), precision)\n",
        "print(colored(\"Recall: \", color=\"red\", attrs=[\"dark\", \"bold\"]), recall)\n",
        "print(colored(\"F1 Score: \", color=\"red\", attrs=[\"dark\", \"bold\"]), f1)\n",
        "\n",
        "# Optionally, print a full classification report (including precision, recall, F1 score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(metrics.classification_report(test_y, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bff62a18",
      "metadata": {
        "papermill": {
          "duration": 0.028498,
          "end_time": "2022-12-01T13:06:44.067740",
          "exception": false,
          "start_time": "2022-12-01T13:06:44.039242",
          "status": "completed"
        },
        "tags": [],
        "id": "bff62a18"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\">Light GBM model with \"count-vectors\" method</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df996824",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:06:44.128395Z",
          "iopub.status.busy": "2022-12-01T13:06:44.127940Z",
          "iopub.status.idle": "2022-12-01T13:06:53.728221Z",
          "shell.execute_reply": "2022-12-01T13:06:53.727018Z"
        },
        "papermill": {
          "duration": 9.635021,
          "end_time": "2022-12-01T13:06:53.731934",
          "exception": false,
          "start_time": "2022-12-01T13:06:44.096913",
          "status": "completed"
        },
        "tags": [],
        "id": "df996824"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from termcolor import colored\n",
        "\n",
        "# Fit the LightGBM model with 'count-vectors' method\n",
        "lgbm = LGBMClassifier()\n",
        "lgbm_model = lgbm.fit(x_train_count.astype(\"float64\"), train_y)\n",
        "\n",
        "# Cross-validation accuracy score\n",
        "accuracy = cross_val_score(lgbm_model,\n",
        "                           x_test_count.astype(\"float64\"),\n",
        "                           test_y,\n",
        "                           cv=20).mean()\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = lgbm_model.predict(x_test_count.astype(\"float64\"))\n",
        "\n",
        "# Calculate precision, recall, and F1 score using sklearn\n",
        "precision = metrics.precision_score(test_y, y_pred)\n",
        "recall = metrics.recall_score(test_y, y_pred)\n",
        "f1 = metrics.f1_score(test_y, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(colored(\"\\nLight GBM model with 'count-vectors' method\", color=\"red\", attrs=[\"dark\", \"bold\"]))\n",
        "print(colored(\"Accuracy ratio: \", color=\"red\", attrs=[\"dark\", \"bold\"]), accuracy)\n",
        "print(colored(\"Precision: \", color=\"red\", attrs=[\"dark\", \"bold\"]), precision)\n",
        "print(colored(\"Recall: \", color=\"red\", attrs=[\"dark\", \"bold\"]), recall)\n",
        "print(colored(\"F1 Score: \", color=\"red\", attrs=[\"dark\", \"bold\"]), f1)\n",
        "\n",
        "# Optionally, print a full classification report (including precision, recall, F1 score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(metrics.classification_report(test_y, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f6dcd50",
      "metadata": {
        "papermill": {
          "duration": 0.028665,
          "end_time": "2022-12-01T13:06:53.792748",
          "exception": false,
          "start_time": "2022-12-01T13:06:53.764083",
          "status": "completed"
        },
        "tags": [],
        "id": "0f6dcd50"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\"> Light GBM model with \"tf-idf\" method</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a42e9ec3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:06:53.852259Z",
          "iopub.status.busy": "2022-12-01T13:06:53.851722Z",
          "iopub.status.idle": "2022-12-01T13:07:10.638480Z",
          "shell.execute_reply": "2022-12-01T13:07:10.637348Z"
        },
        "papermill": {
          "duration": 16.820637,
          "end_time": "2022-12-01T13:07:10.642147",
          "exception": false,
          "start_time": "2022-12-01T13:06:53.821510",
          "status": "completed"
        },
        "tags": [],
        "id": "a42e9ec3"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from lightgbm import LGBMClassifier\n",
        "from termcolor import colored\n",
        "\n",
        "# Fit the LightGBM model\n",
        "lgbm = LGBMClassifier()\n",
        "lgbm_model = lgbm.fit(x_train_count.astype(\"float64\"), train_y)\n",
        "\n",
        "# Cross-validation accuracy score\n",
        "accuracy = cross_val_score(lgbm_model,\n",
        "                           x_test_count.astype(\"float64\"),\n",
        "                           test_y,\n",
        "                           cv=20).mean()\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = lgbm_model.predict(x_test_count.astype(\"float64\"))\n",
        "\n",
        "# Calculate precision, recall, F1 score using sklearn\n",
        "precision = metrics.precision_score(test_y, y_pred)\n",
        "recall = metrics.recall_score(test_y, y_pred)\n",
        "f1 = metrics.f1_score(test_y, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(colored(\"\\nLight GBM model with 'count-vectors' method\", color=\"red\", attrs=[\"dark\", \"bold\"]))\n",
        "print(colored(\"Accuracy ratio: \", color=\"red\", attrs=[\"dark\", \"bold\"]), accuracy)\n",
        "print(colored(\"Precision: \", color=\"red\", attrs=[\"dark\", \"bold\"]), precision)\n",
        "print(colored(\"Recall: \", color=\"red\", attrs=[\"dark\", \"bold\"]), recall)\n",
        "print(colored(\"F1 Score: \", color=\"red\", attrs=[\"dark\", \"bold\"]), f1)\n",
        "\n",
        "# Optionally, print a full classification report (including precision, recall, F1 score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(metrics.classification_report(test_y, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c188bc0c",
      "metadata": {
        "papermill": {
          "duration": 0.031025,
          "end_time": "2022-12-01T13:07:10.707343",
          "exception": false,
          "start_time": "2022-12-01T13:07:10.676318",
          "status": "completed"
        },
        "tags": [],
        "id": "c188bc0c"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\"> ROC AUC (curvature)</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b376f6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:07:10.769651Z",
          "iopub.status.busy": "2022-12-01T13:07:10.769149Z",
          "iopub.status.idle": "2022-12-01T13:07:11.626488Z",
          "shell.execute_reply": "2022-12-01T13:07:11.625378Z"
        },
        "papermill": {
          "duration": 0.89282,
          "end_time": "2022-12-01T13:07:11.630318",
          "exception": false,
          "start_time": "2022-12-01T13:07:10.737498",
          "status": "completed"
        },
        "tags": [],
        "id": "35b376f6"
      },
      "outputs": [],
      "source": [
        "y = train_y\n",
        "X = x_train_count.astype(\"float64\")\n",
        "\n",
        "logit_roc_auc = roc_auc_score(y, lgbm_model.predict(X))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y, lgbm_model.predict_proba(X)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest Model**"
      ],
      "metadata": {
        "id": "JywscySCP7Cg"
      },
      "id": "JywscySCP7Cg"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "id": "kHUW3A4yQBEY"
      },
      "id": "kHUW3A4yQBEY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "# Assuming a CSV file where 'text' is the tweet text and 'label' is the target (1 for hate speech, 0 for non-hate speech)\n",
        "df = pd.read_csv('/train.csv')\n",
        "ds = pd.read_csv('/test.csv')\n",
        "\n",
        "# Split the data into features (X) and labels (y)\n",
        "X = df['tweet']\n",
        "y = df['label']\n",
        "\n",
        "# Split the dataset into training and testing sets (65% training, 35% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
        "\n",
        "# Text preprocessing: Convert text to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)  # You can adjust max_features as needed\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the Random Forest model\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust n_estimators\n",
        "rf_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")"
      ],
      "metadata": {
        "id": "JSpYDhenQJ8F"
      },
      "id": "JSpYDhenQJ8F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4kPR_gnSBEc5"
      },
      "id": "4kPR_gnSBEc5"
    },
    {
      "cell_type": "markdown",
      "id": "045e0d35",
      "metadata": {
        "papermill": {
          "duration": 0.03295,
          "end_time": "2022-12-01T13:07:11.694329",
          "exception": false,
          "start_time": "2022-12-01T13:07:11.661379",
          "status": "completed"
        },
        "tags": [],
        "id": "045e0d35"
      },
      "source": [
        "<a id='top'></a>\n",
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "<p style=\"background-color:#4D1873 ;font-family:arial;color:#FFFFFF;font-size:170%;text-align:center;border-radius:55px 1px;\">ESTIMATION OVER TEST SET</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b662916",
      "metadata": {
        "papermill": {
          "duration": 0.033021,
          "end_time": "2022-12-01T13:07:11.761363",
          "exception": false,
          "start_time": "2022-12-01T13:07:11.728342",
          "status": "completed"
        },
        "tags": [],
        "id": "5b662916"
      },
      "source": [
        "### <span style = \"background:#4D1873; font-size:100%; color:#fff; border-radius:0px;\"> Look at the first 5 rows of the test set</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a469d800",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:07:11.832670Z",
          "iopub.status.busy": "2022-12-01T13:07:11.831558Z",
          "iopub.status.idle": "2022-12-01T13:07:11.845201Z",
          "shell.execute_reply": "2022-12-01T13:07:11.843571Z"
        },
        "papermill": {
          "duration": 0.052335,
          "end_time": "2022-12-01T13:07:11.848025",
          "exception": false,
          "start_time": "2022-12-01T13:07:11.795690",
          "status": "completed"
        },
        "tags": [],
        "id": "a469d800"
      },
      "outputs": [],
      "source": [
        "test_set.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83ec5ea7",
      "metadata": {
        "papermill": {
          "duration": 0.034873,
          "end_time": "2022-12-01T13:07:11.914694",
          "exception": false,
          "start_time": "2022-12-01T13:07:11.879821",
          "status": "completed"
        },
        "tags": [],
        "id": "83ec5ea7"
      },
      "source": [
        "## <mark>Here we encode values of \"tweet\" column of test set with \"count-vectors\" method.</mark>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a8ef39d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:07:11.982156Z",
          "iopub.status.busy": "2022-12-01T13:07:11.980985Z",
          "iopub.status.idle": "2022-12-01T13:07:13.049750Z",
          "shell.execute_reply": "2022-12-01T13:07:13.048625Z"
        },
        "papermill": {
          "duration": 1.104477,
          "end_time": "2022-12-01T13:07:13.052483",
          "exception": false,
          "start_time": "2022-12-01T13:07:11.948006",
          "status": "completed"
        },
        "tags": [],
        "id": "4a8ef39d"
      },
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(train_x)\n",
        "test_set = vectorizer.transform(test_set[\"tweet\"])\n",
        "test_set.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b769b786",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-01T13:07:13.117442Z",
          "iopub.status.busy": "2022-12-01T13:07:13.116941Z",
          "iopub.status.idle": "2022-12-01T13:07:13.298571Z",
          "shell.execute_reply": "2022-12-01T13:07:13.297208Z"
        },
        "papermill": {
          "duration": 0.228212,
          "end_time": "2022-12-01T13:07:13.311738",
          "exception": false,
          "start_time": "2022-12-01T13:07:13.083526",
          "status": "completed"
        },
        "tags": [],
        "id": "b769b786"
      },
      "outputs": [],
      "source": [
        "lgbm_model.predict(test_set.astype(\"float\"))[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gG3eXKWvzhCx"
      },
      "id": "gG3eXKWvzhCx"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from termcolor import colored\n",
        "\n",
        "# Fit the SVM model\n",
        "svm = SVC()\n",
        "svm_model = svm.fit(x_train_count.astype(\"float64\"), train_y)\n",
        "\n",
        "# Cross-validation accuracy score\n",
        "accuracy = cross_val_score(svm_model,\n",
        "                           x_test_count.astype(\"float64\"),\n",
        "                           test_y,\n",
        "                           cv=20).mean()\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = svm_model.predict(x_test_count.astype(\"float64\"))\n",
        "\n",
        "# Calculate precision, recall, and F1 score using sklearn\n",
        "precision = metrics.precision_score(test_y, y_pred)\n",
        "recall = metrics.recall_score(test_y, y_pred)\n",
        "f1 = metrics.f1_score(test_y, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(colored(\"\\nSVM model with 'count-vectors' method\", color=\"red\", attrs=[\"dark\", \"bold\"]))\n",
        "print(colored(\"Accuracy ratio: \", color=\"red\", attrs=[\"dark\", \"bold\"]), accuracy)\n",
        "print(colored(\"Precision: \", color=\"red\", attrs=[\"dark\", \"bold\"]), precision)\n",
        "print(colored(\"Recall: \", color=\"red\", attrs=[\"dark\", \"bold\"]), recall)\n",
        "print(colored(\"F1 Score: \", color=\"red\", attrs=[\"dark\", \"bold\"]), f1)\n",
        "\n",
        "# Optionally, print a full classification report (including precision, recall, F1 score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(metrics.classification_report(test_y, y_pred))\n"
      ],
      "metadata": {
        "id": "62MeUH37E-SG"
      },
      "id": "62MeUH37E-SG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion \n",
        "\n",
        "- We used the **Twitter Sentiment Analysis** dataset and explored the data in various ways.\n",
        "- We prepared the tweet text data by removing unnecessary elements like special characters, URLs, etc.\n",
        "- We trained a model based on **TensorFlow** with appropriate settings for text classification.\n",
        "- We evaluated the model using various evaluation metrics to assess its performance.\n",
        "- If you're interested in working on any text-based project, you can apply the same methodology. However, you may need to adjust a few settings, such as column names and preprocessing steps, depending on your dataset.\n",
        "- We specifically worked on a **binary classification** problem, where the task is to classify the tweets into two categories (e.g., positive or negative sentiment).\n"
      ],
      "metadata": {
        "id": "-uUcB1OxznYO"
      },
      "id": "-uUcB1OxznYO"
    },
    {
      "cell_type": "markdown",
      "id": "7d813576",
      "metadata": {
        "papermill": {
          "duration": 0.065416,
          "end_time": "2022-12-01T13:07:13.436411",
          "exception": false,
          "start_time": "2022-12-01T13:07:13.370995",
          "status": "completed"
        },
        "tags": [],
        "id": "7d813576"
      },
      "source": [
        "<a id='top'></a>\n",
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
        "<p style=\"background-color:#4D1873 ;font-family:arial;color:#FFFFFF;font-size:170%;text-align:center;border-radius:55px 1px;\">VISUALIZATION WITH WORD CLOUD</p>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 239.303853,
      "end_time": "2022-12-01T13:07:23.200172",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-12-01T13:03:23.896319",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}